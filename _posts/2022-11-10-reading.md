---
layout: post
title:  "Reading"
author: "Till Zemann"
date:   2022-11-10 14:36:41 +0200
categories: jekyll update
comments: true
back_to_top_button: true
math: true
positive_reward: true
reward: 3
tags: [interests]
thumbnail: "/images/reading-robot.png"
---

<div class="img-block" style="width: 300px;" align="right">
    <img src="/images/reading-robot.png"/>
</div>

<!--
### Contents
* TOC
{:toc}
-->

### Why you should read & how to read more

Well, let me start by saying that books just smell good. Jokes aside, I recommend you watch <a href="https://youtu.be/lIW5jBrrsS0" target="_blank"> BOOKSTORES: How to Read More Books in the Golden Age of Content</a> before reading this post. It motivates why you and I should read more books and how to do it. I really do hope that you give this video a shot, but be aware that it might really get you excited to find some good books to read, and then there is no stopping. You'll be hooked as well. I also want you to consider all the benefits of reading:

- gain knowledge
- sparking of ideas
- forced meditation (increases attention span & trains focus) and reflection periods
- immersion & fun
- comfy activity (either read outside, in a cafe, in a library or in the evening with some nice ambience)
- low dopamine (reduces the baseline to make other productive activities more rewarding)

... so i would turn the question around and ask why shouldn't you read! (If you come up with something, feel free to write a [comment](https://till2.github.io/comments/).)


### Blogs that you might want to read (high value section)

<em>... if you are interested in AI and/or RL</em>

- Will Dabney's [homepage and blog about Distributional RL](https://willdabney.com/)
- Christopher Olah's [blog](http://colah.github.io/) (really insightful, well explained - Transformers, NLP, Computational Graphs, ...)
- Sam Altman's [blog](https://blog.samaltman.com/) (Fusion, tips on how to do well in research, startups and investing, build productivity and leverage)
- Lilian Weng's [blog](https://lilianweng.github.io/) (insight into OpenAI projects)
- John Schulman's [homepage and blog](http://joschu.net/index.html)
- Antonin Raffin's [homepage](https://araffin.github.io/) (author of StableBaselines3, Learning to drive minutes project with an Autoencoder)
- Juergen Schmidhuber's [homepage](https://people.idsia.ch/~juergen/)
- Julian Schrittwieser's [blog](https://www.furidamu.org/)
- Andrej Karpathy's [blog](https://karpathy.github.io/) and [website](https://karpathy.ai/)
- Alexander Van de Kleut's [blog](https://avandekleut.github.io/) (nice visuals)
- Jessica Stringham's [blog](https://jessicastringham.net/) (looks cool)
- Andrew Ng's [The Batch](https://www.deeplearning.ai/the-batch/tag/letters/)
- George Hotz's [blog](https://geohot.github.io/blog/) and [website](https://geohot.com/)
- Lex Fridman's [video transcripts](https://karpathy.ai/lexicap/index.html)

### Theses that you might want to read

<em>... same gist as above :)</em> 

- Rich Sutton's [thesis about temporal credit assignment in reinforcement learning](http://incompleteideas.net/papers/Sutton-PhD-thesis.pdf)
- David Silver's [thesis about reinforcement learning and simulation-based search in computer go](http://incompleteideas.net/papers/Silver-phd-thesis.pdf) (model-based rl with dyna and mcts, long and short-term memory, rave (?))
- Ilya Sutskever's [thesis about training recurrent neural networks](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)

### Legend
<div class="table-wrap">
    <table class="table">
        <tr>
            <td><strong>Label</strong></td>
            <td><strong>Dot</strong></td>
        </tr>
        <tr>
        	<td><strong>Currently reading</strong> this book.</td>
        	<td>游릭</td>
        </tr>
		<tr>
        	<td><strong>Already read</strong> it.</td>
        	<td>游댯</td>
        </tr>
        <tr>
        	<td><strong>Abandoned</strong> the book.</td>
        	<td>游댮</td>
        </tr>
		<tr>
        	<td>On my <strong>future</strong> reading list.</td>
        	<td>游리</td>
        </tr>
	</table>
</div>


### What i'm currently reading

#### Philosophy
<游댯> Computing Machinery and Intelligence: K칬nnen Maschinen denken? <br>

#### Artificial Intelligence (AI)
<游릭> Genius Makers: The Mavericks Who Brought AI to Google, Facebook, and the World

#### Reinforcement Learning (RL)
<游릭> Reinforcement Learning: An Introduction (second edition) <br>
<游댯> Foundations of Deep Reinforcement Learning <br>
<游댯> Deep Reinforcement Learning Hands-On <br>
<游댯> Deep Learning Illustrated <br>
<游댯> Neural Networks from Scratch in Python <br>
<游댮> Principles of Synthetic Intelligence <br>
<游댮> Deep Reinforcement Learning in Unity <br>
<游릭> Intelligent Agents with OpenAI Gym <br>
<游릭> Deep Reinforcement Learning <br>
<游릭> Reinforcement Learning: Industrial Applications of Intelligent Agents <br>
<游리> Distributional Reinforcement Learning (2023) <br>

#### Physics
<游댯> Chaos: The amazing science of the unpredictable <br>
<游릭> Surely you're joking, Mr. Feynman! <br>

#### Writing & Presentation
<游릭> How to write clearly <br>
<游리> Research data visualization and scientific graphics <br>

#### Math
<游댯> Konkrete Mathematik (nicht nur) f칲r Informatiker <br>
<游댯> Mathematik f칲r angewandte Wissenschaften <br>
<游댯> Funktionentheorie: Eine Einf칲hrung <br>
<游댯> Pi und die Primzahlen <br>
<游댯> Elementare Differentialgeometrie (nicht nur) f칲r Informatiker <br>
<游댯> Mathematics for Machine Learning <br>
<游리> 칖ber die Hypothesen, welche der Geometrie zu Grunde liegen <br>

#### Architecture & Design
<游댯>  Kleine  H칛user unter 100m: Gro른 Wohnqualit칛t durch kreative Konzepte <br>
<游리>  Homes for our time: Contemporary Houses around the World <br>

#### Cryptocurrencies
<游댯> Blockchain: Grundlagen, Anwendungsszenarien und Nutzungspotenziale <br>
<游댮> Bitcoin: Hard money you can't fuck with <br>

### Future reading

<游리> Carl Sagan: Contact <br>
<游리> Carl Sagan: Cosmos <br>
<游리> Love & Math <br>
<游리> The daily stoic: Meditations on wisdom, perseverance, and the art of living <br>


### Research papers

<游댯> Monte-Carlo Tree Search (MCTS) <br>
<游릭> Multi-Agent Pathfinding (-multiple papers )<br>
<游리> MuZero (Planning with a learned model) <br>
<游리> AlphaTensor <br>


<!-- Future update: Online courses and lectures -->
<!-- https://theoreticalminimum.com/courses -->


<!-- In-Text Citing -->
<!-- 
You can...
- use bullet points
1. use
2. ordered
3. lists


-- Math --
$\hat{s} = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \mu)^2$ 

-- Images --
<div class="img-block" style="width: 800px;">
    <img src="/images/lofi_art.png"/>
    <span><strong>Fig 1.1.</strong> Agent and Environment interactions</span>
</div>

-- Links --
[(k-fold) Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)

{% highlight python %}
@jit
def f(x)
    print("hi")
# does cool stuff
{% endhighlight %}

-- Highlights --
AAABC `ASDF` __some bold text__

-- Colors --
The <strong style="color: #1E72E7">joint distribution</strong> of $X$ and $Y$ is written as $P(X, Y)$.
The <strong style="color: #ED412D">marginal distribution</strong> on the other hand can be written out as a table.
-->


<!-- ### References -->

<!-- Ressources -->
[RESSOURCE]: LINK


<!-- Optional Comment Section-->
{% if page.comments %}
<p class="vspace"></p>
<a class="commentlink" role="button" href="/comments/">Share your thoughts.</a> <!-- role="button"  -->
{% endif %}

<!-- Optional Back to Top Button -->
{% if page.back_to_top_button %}
<script src="https://unpkg.com/vanilla-back-to-top@7.2.1/dist/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 40,
  backgroundColor: 'rgb(255, 255, 255, 0.7)', /* 30,144,255, 0.7 */
  textColor: '#4a4946'
})</script>
{% endif %}
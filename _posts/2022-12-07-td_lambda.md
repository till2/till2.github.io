---
layout: post
title:  "TD(Î»)"
author: "Till Zemann"
date:   2022-12-07 14:36:41 +0200
categories: jekyll update
comments: true
back_to_top_button: true
math: true
positive_reward: true
reward: 1
tags: [reinforcement learning]
thumbnail: "/images/td_lambda/td_to_monte_carlo.png" 
---

<!-- alternative thumbnail: td_lambda_illustration.png -->

<!-- for multiple tags use a list: [hello1, hello2] -->

<!--
### Contents
* TOC
{:toc}
-->

<!--
TODO:
- add image links to References
-->

### Intro

If we want to use n-step TD-rollouts, there are some caveats that should be considered - we'll adress them in this post.

<div class="img-block" style="width: 350px;">
    <img src="/images/td_lambda/td_to_monte_carlo.png"/>
</div>


### Example: 3-step update

<svg width="800" height="150" version="1.1" xmlns="http://www.w3.org/2000/svg">
	<ellipse stroke="black" stroke-width="1" fill="none" cx="312.5" cy="77.5" rx="30" ry="30"/>
	<text x="303.5" y="83.5" font-family="Times New Roman" font-size="20">s&#8321;</text>
	<ellipse stroke="black" stroke-width="1" fill="none" cx="158.5" cy="77.5" rx="30" ry="30"/>
	<text x="149.5" y="83.5" font-family="Times New Roman" font-size="20">s&#8320;</text>
	<ellipse stroke="black" stroke-width="1" fill="none" cx="468.5" cy="77.5" rx="30" ry="30"/>
	<text x="459.5" y="83.5" font-family="Times New Roman" font-size="20">s&#8322;</text>
	<ellipse stroke="black" stroke-width="1" fill="none" cx="621.5" cy="77.5" rx="30" ry="30"/>
	<text x="612.5" y="83.5" font-family="Times New Roman" font-size="20">s&#8323;</text>
	<polygon stroke="black" stroke-width="1" points="188.5,77.5 282.5,77.5"/>
	<polygon fill="black" stroke-width="1" points="282.5,77.5 274.5,72.5 274.5,82.5"/>
	<text x="193.5" y="70.5" font-family="Times New Roman" font-size="20">a&#8320;~&#960;(s&#8320;)</text>
	<polygon stroke="black" stroke-width="1" points="342.5,77.5 438.5,77.5"/>
	<polygon fill="black" stroke-width="1" points="438.5,77.5 430.5,72.5 430.5,82.5"/>
	<text x="348.5" y="70.5" font-family="Times New Roman" font-size="20">a&#8321;~&#960;(s&#8321;)</text>
	<polygon stroke="black" stroke-width="1" points="498.5,77.5 591.5,77.5"/>
	<polygon fill="black" stroke-width="1" points="591.5,77.5 583.5,72.5 583.5,82.5"/>
	<text x="503.5" y="70.5" font-family="Times New Roman" font-size="20">a&#8322;~&#960;(s&#8322;)</text>

	<text x="243.5" y="98.5" font-family="Times New Roman" font-size="20">r&#8321;</text>
	<text x="408.5" y="98.5" font-family="Times New Roman" font-size="20">r&#8322;</text>
	<text x="563.5" y="98.5" font-family="Times New Roman" font-size="20">r&#8323;</text>
</svg>

The TD-Error based on 3 timesteps, in which we collected the rewards $r_1, r_2$ and $r_3$ becomes:

$$
\Delta_3 Q(s_0, a_0) = r_1 + \gamma r_2 + \gamma^2 r_3 + \gamma^3 arg\max_{a'} Q^{\pi}(s_3, a')
$$

### Problem

- longer TD-rollouts have a high variance (because the space of n-step rollouts is larger than the space of 1-step rollouts) $\rightarrow$ we should attribute a lower weight to future errors

### Solution: Weighted average $\Delta(\lambda)$ with hyperparam. $\lambda \in [0,1]$

Exponentially weighted average of TD-Errors:

$$
\Delta(\lambda) = (1 - \lambda) \sum_{k=0}^{\infty} \lambda^{k} \Delta_{k+1} Q(s,a)
$$

- weighted towards nearer-term TD-Errors
- if we set the $\lambda = 0$, we get the usual TD(1-step) Error


To examine the weighting, here are a couple of examples:
<div class="img-block" style="width: 500px;">
    <img src="/images/td_lambda/lambda_vals.png"/>
</div>


### Temporal-Difference learning algorithm = TD($\lambda$):

__Input:__ An MDP.
__Output:__ A policy $\pi \approx \pi^{\*}$

0. While not converged:<br>
	1. Sample an episode with n steps using the policy $\pi$
	2. $\Delta(\lambda) \leftarrow \sum_{k=1}^{n} (1 - \lambda) \lambda^{k-1} \Delta_k Q(s,a)$ // get the weighted average 
	3. $Q^{\pi}(s,a) \leftarrow (1 - \alpha)Q^{\pi}(s,a) + \alpha \Delta(\lambda)$
	4. Improve $\pi$ by increasing $\pi(arg\max_a Q^{\pi}(s,a) \| s)$

1. Return policy $\pi$ with $\pi(s) = arg\max_a Q^{\pi}(s,a)$ for all $s \in S$.


### TD($\lambda$) vs TD(0)

By capturing long-term dependencies, TD($\lambda$) should work better than TD(0).


<!-- In-Text Citing -->
<!-- 

Referencing equations:
$$
\begin{equation} \tag{1}\label{eq:1}
x=y
\end{equation}
$$
I reference equation \eqref{eq:1}


You can...
- use bullet points
1. use
2. ordered
3. lists

-- Math --
$\hat{s} = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \mu)^2$ 

-- Images --
<div class="img-block" style="width: 800px;">
    <img src="/images/lofi_art.png"/>
    <span><strong>Fig 1.1.</strong> Agent and Environment interactions</span>
</div>

-- Links --
[(k-fold) Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)

```c
for(int i=0; i<comm_sz; i++){
	print("%d\n", i);
}
```

<div class="output">
result: 42
</div>

{% highlight python %}
@jit
def f(x)
    print("hi")
# does cool stuff
{% endhighlight %}

-- Highlights --
AAABC `ASDF` __some bold text__

-- Colors --
The <strong style="color: #1E72E7">joint distribution</strong> of $X$ and $Y$ is written as $P(X, Y)$.
The <strong style="color: #ED412D">marginal distribution</strong> on the other hand can be written out as a table.
-->



### References

1. Thumbnail from [Mark Lee 2005-01-04][mark-lee-thumbnail].
2. [Sutton & Barto: Reinforcement Learning][sab]

<!-- Ressources -->
[RESSOURCE]: LINK
[mark-lee-thumbnail]: http://incompleteideas.net/book/ebook/node73.html
[sab]: http://incompleteideas.net/book/the-book-2nd.html

<!-- Optional Comment Section-->
{% if page.comments %}
<p class="vspace"></p>
<a class="commentlink" role="button" href="/comments/">Post a comment.</a> <!-- role="button"  -->
{% endif %}

<!-- Optional Back to Top Button -->
{% if page.back_to_top_button %}
<script src="https://unpkg.com/vanilla-back-to-top@7.2.1/dist/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 40,
  backgroundColor: 'rgb(255, 255, 255, 0.7)', /* 30,144,255, 0.7 */
  textColor: '#4a4946'
})</script>
{% endif %} 
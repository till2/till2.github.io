---
layout: post
title:  "Monte-Carlo Tree Search"
author: "Till Zemann"
date:   2022-12-08 02:00:41 +0200
categories: jekyll update
comments: true
back_to_top_button: true
math: true
positive_reward: true
reward: 1
tags: [reinforcement learning, search]
thumbnail: "/images/mcts/mcts_4steps.png" 
---

<!-- alternative thumbnail: td_lambda_illustration.png -->

<!-- for multiple tags use a list: [hello1, hello2] -->

<!--
### Contents
* TOC
{:toc}
-->

<!--
TODO:
- add image links to References
-->

### Intro

If we want to use n-step TD-rollouts, there are some caveats that should be considered - we'll adress them in this post.

<div class="img-block" style="width: 800px;">
    <img src="/images/mcts/mcts_4steps.png"/>
</div>

__Monte-Carlo Tree Search Algorithm:__

1. __Node selection:__
- use a (stochastic) selection policy $\pi^{s}$ to select nodes until we are at a node with no children

2. __Expansion:__
- expand this node (add one or more children according to the policy $\pi^{s}$)

3. __Simulation:__
- sample one episode according to $\pi$ (could be another policy than $\pi^s$)
- observe the value/reward (could be the reward or outcome of a game, i.e. if you won or lost)

4. __Backpropagation:__
- update $V^{\pi}$ (or $Q^{\pi}$) for all nodes along the trajectory starting from the bottom (= bootstrapping)
- i.e. start with $\Delta V^{\pi}(s_8) = r_9 + \gamma V^{\pi}(s_9)$ for updating the value of state $s_8$


<div class="img-block" style="width: 800px;">
    <img src="/images/mcts/mcts_vl.jpg"/>
</div>


### Parallelization

There are three main approaches to parallelization, and the one that sounds most interesting to me (because of simplicity) is
1. `leaf parallelization`:
- execute multiple playouts (=rollouts) from one leaf node in parallel.

For completeness, the other two approaches are:
2. `root parallelization`:
- build _independent_ trees in parallel and use all the roots (e.g. mean of all $s'$ one step from the root with $S_t = s_{\text{root}}, S_{t+1} = s'$) to make the final decision
- probably takes too much memory for a small project

3. `tree parallelization`:
- build one tree in parallel, using mutually exclusive write-access (i.e. a mutex) 
- this is hard to implement

<!-- ### AlphaGo Zero -->




<!-- In-Text Citing -->
<!-- 

Referencing equations:
$$
\begin{equation} \tag{1}\label{eq:1}
x=y
\end{equation}
$$
I reference equation \eqref{eq:1}


You can...
- use bullet points
1. use
2. ordered
3. lists

-- Math --
$\hat{s} = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \mu)^2$ 

-- Images --
<div class="img-block" style="width: 800px;">
    <img src="/images/lofi_art.png"/>
    <span><strong>Fig 1.1.</strong> Agent and Environment interactions</span>
</div>

-- Links --
[(k-fold) Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)

```c
for(int i=0; i<comm_sz; i++){
	print("%d\n", i);
}
```

<div class="output">
result: 42
</div>

{% highlight python %}
@jit
def f(x)
    print("hi")
# does cool stuff
{% endhighlight %}

-- Highlights --
AAABC `ASDF` __some bold text__

-- Colors --
The <strong style="color: #1E72E7">joint distribution</strong> of $X$ and $Y$ is written as $P(X, Y)$.
The <strong style="color: #ED412D">marginal distribution</strong> on the other hand can be written out as a table.
-->



### References

1. Thumbnail from [Wikipedia: MCTS_Algorithm][thumb]
2. Tree example from Scheffer, T. Intelligent Data Analysis 2: Reinforcement Learning 2
3. [Sutton & Barto: Reinforcement Learning][sab]
4. Parallelization techniques from [Wikipedia: Monte Carlo tree search][wiki-mcts].

<!-- Ressources -->
[RESSOURCE]: LINK
[thumb]: https://en.wikipedia.org/wiki/Monte_Carlo_tree_search#/media/File:MCTS_Algorithm.png
[sab]: http://incompleteideas.net/book/the-book-2nd.html
[wiki-mcts]: https://en.wikipedia.org/wiki/Monte_Carlo_tree_search

<!-- Optional Comment Section-->
{% if page.comments %}
<p class="vspace"></p>
<a class="commentlink" role="button" href="/comments/">Post a comment.</a> <!-- role="button"  -->
{% endif %}

<!-- Optional Back to Top Button -->
{% if page.back_to_top_button %}
<script src="https://unpkg.com/vanilla-back-to-top@7.2.1/dist/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 40,
  backgroundColor: 'rgb(255, 255, 255, 0.7)', /* 30,144,255, 0.7 */
  textColor: '#4a4946'
})</script>
{% endif %} 